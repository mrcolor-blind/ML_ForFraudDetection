{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb462775",
   "metadata": {},
   "source": [
    "# **Preparación de los datos**\n",
    "\n",
    "- Este archivo prepara los datos, dejándolos listos para ser modelados.\n",
    "- Utiliza las variantes Base, III, y V, ya previamente limpios (transformados).\n",
    "- Es necesario tener en la misma carpeta los csv: \"base_clean.csv\", \"viii_clean.csv\", y \"vv_clean.csv\".\n",
    "- La salida del archivo es una carpeta \"prepared_data\" conteniendo los archivos .pkl para ser usados en la etapa de modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cca7783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List, Optional, Union\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003ff5d",
   "metadata": {},
   "source": [
    "### Función de balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54abcf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, RandomOverSampler\n",
    "\n",
    "def oversample_train(X_train: pd.DataFrame, y_train: pd.Series, random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Balancea el conjunto de entrenamiento usando oversampling (SMOTE o SMOTENC).\n",
    "    Si no es posible aplicar SMOTE por pocos fraudes, usa RandomOverSampler.\n",
    "    \"\"\"\n",
    "    X = X_train.copy()\n",
    "    y = y_train.copy()\n",
    "\n",
    "    # --- 1. Normalizar tipos ---\n",
    "    # bool -> int\n",
    "    for col in X.select_dtypes(include=[\"bool\"]).columns:\n",
    "        X[col] = X[col].astype(int)\n",
    "    # object/category -> category\n",
    "    for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "        X[col] = X[col].astype(\"category\")\n",
    "\n",
    "    # --- 2. Identificar categóricas para SMOTENC ---\n",
    "    categorical_idx = [\n",
    "        i for i, dt in enumerate(X.dtypes) if str(dt) == \"category\"\n",
    "    ] or None\n",
    "\n",
    "    # --- 3. Ajustar k_neighbors dinámicamente ---\n",
    "    cnt = Counter(y)\n",
    "    min_class = min(cnt, key=cnt.get)\n",
    "    n_min = cnt[min_class]\n",
    "    k_neighbors = max(1, min(5, n_min - 1))  # mínimo 1, máximo 5\n",
    "\n",
    "    print(f\"Fraudes en train={n_min}. Usando k_neighbors={k_neighbors}.\")\n",
    "\n",
    "    # --- 4. Elegir sampler ---\n",
    "    if n_min <= 1:\n",
    "        print(\"Muy pocos fraudes, usando RandomOverSampler.\")\n",
    "        sampler = RandomOverSampler(random_state=random_state)\n",
    "    else:\n",
    "        if categorical_idx:\n",
    "            sampler = SMOTENC(\n",
    "                categorical_features=categorical_idx,\n",
    "                k_neighbors=k_neighbors,\n",
    "                random_state=random_state\n",
    "            )\n",
    "        else:\n",
    "            sampler = SMOTE(\n",
    "                k_neighbors=k_neighbors,\n",
    "                random_state=random_state\n",
    "            )\n",
    "\n",
    "    # --- 5. Fit + resample ---\n",
    "    X_res, y_res = sampler.fit_resample(X, y)\n",
    "    return X_res, y_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d92d9b",
   "metadata": {},
   "source": [
    "### Funciones utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3f7c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"fraud_bool\"\n",
    "MONTH_COL = \"month\"\n",
    "\n",
    "def check_required_columns(df: pd.DataFrame, name: str):\n",
    "    missing = [c for c in [TARGET_COL, MONTH_COL] if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{name}: faltan columnas requeridas {missing}\")\n",
    "\n",
    "def split_by_month(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Devuelve dict con splits temporales para Base:\n",
    "    - train_months: 1–5\n",
    "    - val_month: 6\n",
    "    - test_months: 7–8\n",
    "    \"\"\"\n",
    "    # Normalizamos mes a int por si viene como string\n",
    "    df = df.copy()\n",
    "    df[MONTH_COL] = pd.to_numeric(df[MONTH_COL], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    splits = {\n",
    "        \"train\": df[df[MONTH_COL].between(1, 5, inclusive=\"both\")],\n",
    "        \"val\":   df[df[MONTH_COL] == 6],\n",
    "        \"test\":  df[df[MONTH_COL].between(7, 8, inclusive=\"both\")],\n",
    "    }\n",
    "    # Verificación mínima\n",
    "    for k, v in splits.items():\n",
    "        if len(v) == 0:\n",
    "            raise ValueError(f\"Split '{k}' quedó vacío. Revisa la columna 'month' y sus valores.\")\n",
    "    return splits\n",
    "\n",
    "def align_feature_space(\n",
    "    ref_X: pd.DataFrame, other_X: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Alinea columnas de other_X a las de ref_X:\n",
    "    - agrega columnas faltantes con 0\n",
    "    - reordena columnas\n",
    "    - descarta columnas extra no presentes en ref_X\n",
    "    \"\"\"\n",
    "    other = other_X.copy()\n",
    "    # Añadir faltantes\n",
    "    for col in ref_X.columns:\n",
    "        if col not in other.columns:\n",
    "            other[col] = 0\n",
    "    # Filtrar extras\n",
    "    other = other[ref_X.columns]\n",
    "    return other\n",
    "\n",
    "def get_X_y(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    X = df.drop(columns=[TARGET_COL])\n",
    "    y = df[TARGET_COL].astype(int)\n",
    "    return X, y\n",
    "\n",
    "def infer_categorical_indices(X: pd.DataFrame) -> Optional[List[int]]:\n",
    "    \"\"\"\n",
    "    Si aún tienes columnas categóricas (dtype 'object' o 'category') sin One-Hot,\n",
    "    devuelve índices para SMOTENC. Si no, devuelve None.\n",
    "    \"\"\"\n",
    "    cat_cols = [i for i, (col, dt) in enumerate(zip(X.columns, X.dtypes))\n",
    "                if str(dt) in (\"object\", \"category\")]\n",
    "    return cat_cols if len(cat_cols) > 0 else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd36204",
   "metadata": {},
   "source": [
    "### 5) Carga de CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6169ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(\"base_clean.csv\")\n",
    "v3   = pd.read_csv(\"viii_clean.csv\")  # Variant III\n",
    "v5   = pd.read_csv(\"vv_clean.csv\")    # Variant V\n",
    "\n",
    "check_required_columns(base, \"base_clean.csv\")\n",
    "check_required_columns(v3,   \"viii_clean.csv (Variant III)\")\n",
    "check_required_columns(v5,   \"vv_clean.csv (Variant V)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a64d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud_bool                        int64\n",
      "income                          float64\n",
      "name_email_similarity           float64\n",
      "prev_address_months_count       float64\n",
      "current_address_months_count    float64\n",
      "                                 ...   \n",
      "device_os_linux                   int64\n",
      "device_os_macintosh               int64\n",
      "device_os_other                   int64\n",
      "device_os_windows                 int64\n",
      "device_os_x11                     int64\n",
      "Length: 62, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(base.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a875b",
   "metadata": {},
   "source": [
    "### Splits Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "439f3499",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_base = split_by_month(base)\n",
    "train_base = splits_base[\"train\"]\n",
    "val_base   = splits_base[\"val\"]\n",
    "test_base  = splits_base[\"test\"]\n",
    "\n",
    "X_train_base, y_train_base = get_X_y(train_base)\n",
    "X_val_base,   y_val_base   = get_X_y(val_base)\n",
    "X_test_base,  y_test_base  = get_X_y(test_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1238fe2a",
   "metadata": {},
   "source": [
    "### Balanceo en conjuntos de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d91fa5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from imblearn.over_sampling import SMOTENC\\n\\n# Indica los índices (posición de columna) que son categóricos\\ncategorical_features = X_train_base.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\\n\\n\\nsmote_nc = SMOTENC(\\n    categorical_features=categorical_features,\\n    random_state=42,\\n    k_neighbors=5,\\n    sampling_strategy=\"auto\"\\n)\\n\\nX_train_bal, y_train_bal = smote_nc.fit_resample(X_train_base, y_train_base)\\n\\n '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# Indica los índices (posición de columna) que son categóricos\n",
    "categorical_features = X_train_base.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "\n",
    "smote_nc = SMOTENC(\n",
    "    categorical_features=categorical_features,\n",
    "    random_state=42,\n",
    "    k_neighbors=5,\n",
    "    sampling_strategy=\"auto\"\n",
    ")\n",
    "\n",
    "X_train_bal, y_train_bal = smote_nc.fit_resample(X_train_base, y_train_base)\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31f89c",
   "metadata": {},
   "source": [
    "### Preparar conjuntos de evaluación en III y V\n",
    "\n",
    "- Usamos SOLO sus meses 7–8 como \"test externo\"\n",
    "- Alineamos columnas con el espacio de features del train Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee5b1113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def external_test_slice(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[MONTH_COL] = pd.to_numeric(df[MONTH_COL], errors=\"coerce\").astype(\"Int64\")\n",
    "    ext = df[df[MONTH_COL].between(7, 8, inclusive=\"both\")]\n",
    "    if len(ext) == 0:\n",
    "        raise ValueError(\"El conjunto externo quedó vacío (no hay months 7–8).\")\n",
    "    return ext\n",
    "\n",
    "ext_v3 = external_test_slice(v3)\n",
    "ext_v5 = external_test_slice(v5)\n",
    "\n",
    "X_ext_v3, y_ext_v3 = get_X_y(ext_v3)\n",
    "X_ext_v5, y_ext_v5 = get_X_y(ext_v5)\n",
    "\n",
    "# Alinear al espacio de entrenamiento (después del balanceo no cambian columnas)\n",
    "X_ext_v3 = align_feature_space(X_train_base, X_ext_v3)\n",
    "X_ext_v5 = align_feature_space(X_train_base, X_ext_v5)\n",
    "\n",
    "# (Opcional) también alinear val/test internos por consistencia absoluta:\n",
    "X_val_base  = align_feature_space(X_train_base, X_val_base)\n",
    "X_test_base = align_feature_space(X_train_base, X_test_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df869143",
   "metadata": {},
   "source": [
    "### Salidas listas para modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6d940db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prepared_data/y_test_v5.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "prepared = {\n",
    "    # Base (para entrenar/validar/probar internamente)\n",
    "    \"X_train_base\": X_train_base,       \"y_train_base\": y_train_base,\n",
    "    # \"X_train_bal\": X_train_bal,         \"y_train_bal\": y_train_bal,  # <- usar este para entrenar\n",
    "    \"X_val_base\": X_val_base,           \"y_val_base\": y_val_base,\n",
    "    \"X_test_base\": X_test_base,         \"y_test_base\": y_test_base,\n",
    "\n",
    "    # Evaluación externa (generalización/robustez)\n",
    "    \"X_test_v3\": X_ext_v3,              \"y_test_v3\": y_ext_v3,   # Variant III (meses 7–8)\n",
    "    \"X_test_v5\": X_ext_v5,              \"y_test_v5\": y_ext_v5,   # Variant V   (meses 7–8)\n",
    "}\n",
    "\n",
    "\n",
    "# Carpeta de salida\n",
    "os.makedirs(\"prepared_data\", exist_ok=True)\n",
    "\n",
    "# Guardar cada dataset como pickle (rápido y conserva tipos)\n",
    "joblib.dump(prepared[\"X_train_base\"], \"prepared_data/X_train_base.pkl\")\n",
    "joblib.dump(prepared[\"y_train_base\"], \"prepared_data/y_train_base.pkl\")\n",
    "\n",
    "joblib.dump(prepared[\"X_val_base\"], \"prepared_data/X_val_base.pkl\")\n",
    "joblib.dump(prepared[\"y_val_base\"], \"prepared_data/y_val_base.pkl\")\n",
    "\n",
    "joblib.dump(prepared[\"X_test_base\"], \"prepared_data/X_test_base.pkl\")\n",
    "joblib.dump(prepared[\"y_test_base\"], \"prepared_data/y_test_base.pkl\")\n",
    "\n",
    "joblib.dump(prepared[\"X_test_v3\"], \"prepared_data/X_test_v3.pkl\")\n",
    "joblib.dump(prepared[\"y_test_v3\"], \"prepared_data/y_test_v3.pkl\")\n",
    "\n",
    "joblib.dump(prepared[\"X_test_v5\"], \"prepared_data/X_test_v5.pkl\")\n",
    "joblib.dump(prepared[\"y_test_v5\"], \"prepared_data/y_test_v5.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
